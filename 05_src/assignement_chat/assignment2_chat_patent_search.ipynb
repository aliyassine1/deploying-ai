{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# patent search engine"
      ],
      "metadata": {
        "id": "aeB9zHooMnrn"
      },
      "id": "aeB9zHooMnrn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a research scientist, I often come up with new ideas and need to quickly check whether similar inventions already exist. Since the main way to protect and monetize an idea is by filing a patent—especially if it is novel and commercially valuable, I wanted to search existing patents efficiently. The process is tedious and this agent can help patent agent in their search before reviewing to clients their innovation.\n",
        "I received an API key from PatentsView, which provides direct access to USPTO data. I plan to use it as my primary source, since it’s more structured, complete, and accurate. In parallel, I’m also using SerpApi’s free tier to run Google Patents searches and download the corresponding patent PDFs. Since the patent id search can be tedious the patent view api can return more than 10k patents using chatgpt api would not be feasible without ranking the patent first semantically based on similarity with the query and the claim."
      ],
      "metadata": {
        "id": "Ck0VxAYrMlW3"
      },
      "id": "Ck0VxAYrMlW3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# service 1: check if a patent exists"
      ],
      "metadata": {
        "id": "B7SyYTvJMt12"
      },
      "id": "B7SyYTvJMt12"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used keyword search initially,\n",
        "but the results were not that impressive. after retrieval based on claims keyword search i then used a transformer to gte embeddings. Ranked the patents by similarity to the user's query. got the top 10 and then fetched the top 10 full claims to let the llm compare them with the user query. -- i could have used open ai models too the small ones.\n",
        "After that fed it to the LLLM (sorry could not only use the libraries provided since i wanted a small llm that runs on cpu to get embedddings in a fast way).\n",
        "uv add google-search-results was added to the virtual environment."
      ],
      "metadata": {
        "id": "_clvf8_dMwN8"
      },
      "id": "_clvf8_dMwN8"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "from pydantic import BaseModel, ValidationError\n",
        "\n",
        "# ---------- LLM ----------\n",
        "from openai import OpenAI, OpenAIError\n",
        "\n",
        "# ---------- Sentence-Transformers (required for semantic ranking) ----------\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    import torch\n",
        "except ImportError as e:\n",
        "    raise RuntimeError(\n",
        "        \"sentence-transformers is required. Install with: pip install sentence-transformers\"\n",
        "    ) from e\n",
        "\n",
        "# ---------- SerpApi (Google Patents details) ----------\n",
        "try:\n",
        "    import serpapi\n",
        "    from serpapi import GoogleSearch\n",
        "except ImportError:\n",
        "    serpapi = None\n",
        "    GoogleSearch = None\n",
        "    print(\"SerpApi library not found. Please run: pip install google-search-results\")\n",
        "\n",
        "PATENTSVIEW_API_KEY = os.environ.get(\"PATENTSVIEW_API_KEY\")\n",
        "OPENAI_API_KEY      = os.environ.get(\"OPENAI_API_KEY\")\n",
        "SERPAPI_API_KEY     = os.environ.get(\"SERPAPI_API_KEY\")\n",
        "\n",
        "if not PATENTSVIEW_API_KEY:\n",
        "    raise RuntimeError(\"PATENTSVIEW_API_KEY is not set.\")\n",
        "if not OPENAI_API_KEY:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY is not set.\")\n",
        "\n",
        "OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)\n",
        "SERPAPI_API_KEY_SET = bool(SERPAPI_API_KEY) and (serpapi is not None)\n",
        "\n",
        "\n",
        "PATENT_ENDPOINT = \"https://search.patentsview.org/api/v1/patent/\"\n",
        "#to get the patents from the query\n",
        "CLAIMS_ENDPOINT = \"https://search.patentsview.org/api/v1/g_claim/\"   # <-- correct path\n",
        "\n",
        "def _base_headers():\n",
        "    return {\n",
        "        \"X-Api-Key\": PATENTSVIEW_API_KEY,   # <-- correct header key\n",
        "        \"Accept\": \"application/json\"\n",
        "    }\n",
        "\n",
        "# =========================\n",
        "# Models\n",
        "# =========================\n",
        "class Patent(BaseModel):\n",
        "    patent_number: str\n",
        "    application_number: str\n",
        "    title: str\n",
        "    snippet: str\n",
        "    publication_date: str\n",
        "    inventor: str\n",
        "    assignee: str\n",
        "    status: str\n",
        "    patent_link: str\n",
        "    pdf_link: Optional[str] = None\n",
        "    claims_snippet: Optional[str] = None\n",
        "    claims_summary: Optional[str] = None\n",
        "\n",
        "class LLMSummary(BaseModel):\n",
        "    summary_text: str\n",
        "    top_2_relevant_patents: List[Patent]\n",
        "\n",
        "\n",
        "def fetch_patentsview_claims_by_id(patent_id: str, max_claims_per_patent: int = 100) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Fetches all claims for a *specific* patent_id using the /g_claim endpoint.\n",
        "    This is a reliable fallback for when SerpApi fails.\n",
        "    \"\"\"\n",
        "    q_obj = {\"patent_id\": str(patent_id)}\n",
        "    f = [\"claim_sequence\", \"claim_text\"]\n",
        "    o = {\"size\": max_claims_per_patent}\n",
        "    s = [{\"claim_sequence\": \"asc\"}] # Sort claims 1, 2, 3...\n",
        "    body = {\"q\": q_obj, \"f\": f, \"o\": o, \"s\": s}\n",
        "\n",
        "    try:\n",
        "        resp = requests.post(\n",
        "            CLAIMS_ENDPOINT,\n",
        "            headers={**_base_headers(), \"Content-Type\": \"application/json\"},\n",
        "            data=json.dumps(body),\n",
        "            timeout=45\n",
        "        )\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "\n",
        "        claims = data.get(\"g_claims\", [])\n",
        "        if not claims:\n",
        "            print(f\"PatentsView /g_claim had no claims for {patent_id}\")\n",
        "            return None\n",
        "\n",
        "        # Aggregate and return\n",
        "        aggregated_text = \" \".join([c.get(\"claim_text\", \"\") for c in claims if c.get(\"claim_text\")])\n",
        "        return aggregated_text if aggregated_text else None\n",
        "\n",
        "    except requests.HTTPError as e:\n",
        "        status = getattr(e.response, \"status_code\", \"?\")\n",
        "        print(f\"/g_claim HTTP {status} for {patent_id}: {e.response.text if e.response else ''}\")\n",
        "        return None\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"/g_claim connection error for {patent_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# =========================\n",
        "# SerpApi Helper\n",
        "# =========================\n",
        "def fetch_serpapi_details(patent_id: str) -> Tuple[Optional[str], Optional[str]]:\n",
        "    if not SERPAPI_API_KEY_SET:\n",
        "        print(\"SerpApi key not set, skipping detail fetch.\")\n",
        "        return None, None\n",
        "    try:\n",
        "        params = {\n",
        "            \"api_key\": SERPAPI_API_KEY,\n",
        "            \"engine\": \"google_patents_details\",\n",
        "            \"patent_id\": f\"patent/US{patent_id}\",\n",
        "        }\n",
        "        search = GoogleSearch(params)\n",
        "        results = search.get_dict()\n",
        "\n",
        "        if \"error\" in results:\n",
        "            print(f\"SerpApi Error for {patent_id}: {results['error']}\")\n",
        "            return None, None\n",
        "\n",
        "        pdf_link = results.get(\"pdf\")\n",
        "        claims = results.get(\"claims\")\n",
        "\n",
        "        claims_text: Optional[str] = None\n",
        "        if isinstance(claims, list):\n",
        "            pieces = []\n",
        "            for c in claims[:5]:\n",
        "                if isinstance(c, dict):\n",
        "                    pieces.append(str(c.get(\"text\", \"\")))\n",
        "                else:\n",
        "                    pieces.append(str(c))\n",
        "            claims_text = \" \".join(pieces).strip() or None\n",
        "        elif isinstance(claims, str):\n",
        "            claims_text = claims.strip() or None\n",
        "        return pdf_link, claims_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching SerpApi details for {patent_id}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# =========================\n",
        "# Simple keyword helpers\n",
        "# =========================\n",
        "STOPWORDS = {\n",
        "    \"the\", \"a\", \"an\", \"of\", \"and\", \"or\", \"for\", \"to\", \"with\", \"in\", \"on\",\n",
        "    \"at\", \"from\", \"by\", \"that\", \"this\", \"these\", \"those\", \"you\", \"your\",\n",
        "    \"their\", \"its\", \"is\", \"are\", \"was\", \"were\", \"be\", \"being\", \"been\",\n",
        "    \"as\", \"it\", \"into\", \"about\", \"over\", \"under\", \"between\", \"within\"\n",
        "}\n",
        "def _extract_keywords(text: str) -> List[str]:\n",
        "    tokens = re.split(r\"[^a-zA-Z0-9]+\", text.lower())\n",
        "    return [t for t in tokens if len(t) >= 3 and t not in STOPWORDS]\n",
        "def _make_text_value(keywords: List[str]) -> Optional[str]:\n",
        "    return \" \".join(keywords) if keywords else None\n",
        "\n",
        "# =========================\n",
        "# CLAIMS: retrieve claim_text (and patent_id) then aggregate per patent\n",
        "# =========================\n",
        "def fetch_claims_with_text(\n",
        "    search_text: str,\n",
        "    *,\n",
        "    rows_per_call: int = 1000,\n",
        "    max_claims_total: int = 3000,\n",
        "    max_chars_per_patent: int = 4000,\n",
        "    use_any_keywords_fallback: bool = True\n",
        ") -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Query the /g_claim endpoint to retrieve claim_text + patent_id.\n",
        "    Aggregates claim texts PER patent_id (concatenated) and caps length per patent.\n",
        "\n",
        "    Returns:\n",
        "         dict: { patent_id: aggregated_claim_text (<= max_chars_per_patent) }\n",
        "    \"\"\"\n",
        "    keywords = _extract_keywords(search_text)\n",
        "    text_value = _make_text_value(keywords) or search_text\n",
        "\n",
        "    def _do_query(q_obj: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        f = [\"patent_id\", \"claim_sequence\", \"claim_text\"]\n",
        "        o = {\"size\": min(rows_per_call, 1000)}\n",
        "        body = {\"q\": q_obj, \"f\": f, \"o\": o}\n",
        "        resp = requests.post(\n",
        "            CLAIMS_ENDPOINT,\n",
        "            headers={**_base_headers(), \"Content-Type\": \"application/json\"},\n",
        "            data=json.dumps(body),\n",
        "            timeout=45\n",
        "        )\n",
        "        resp.raise_for_status()\n",
        "        return resp.json()\n",
        "\n",
        "    # try phrase OR all-keyword\n",
        "    q_all = {\n",
        "        \"_or\": [\n",
        "            {\"_text_phrase\": {\"claim_text\": search_text}},\n",
        "            {\"_text_all\": {\"claim_text\": text_value}},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        result = _do_query(q_all)\n",
        "        claims = result.get(\"g_claims\", [])  # response key for g_claim\n",
        "\n",
        "        # fallback to any-keywords if needed\n",
        "        if not claims and use_any_keywords_fallback and keywords and len(keywords) > 1:\n",
        "            q_any = {\"_text_any\": {\"claim_text\": text_value}}\n",
        "            result = _do_query(q_any)\n",
        "            claims = result.get(\"g_claims\", [])\n",
        "\n",
        "        # Aggregate per patent and cap size\n",
        "        per_patent: Dict[str, List[str]] = {}\n",
        "        count = 0\n",
        "        for c in claims:\n",
        "            pid = str(c.get(\"patent_id\"))\n",
        "            ctext = c.get(\"claim_text\", \"\")\n",
        "            if not pid or not ctext:\n",
        "                continue\n",
        "            per_patent.setdefault(pid, []).append(ctext)\n",
        "            count += 1\n",
        "            if count >= max_claims_total:\n",
        "                break\n",
        "\n",
        "        aggregated: Dict[str, str] = {}\n",
        "        for pid, lst in per_patent.items():\n",
        "            joined = \" \".join(lst)\n",
        "            if len(joined) > max_chars_per_patent:\n",
        "                joined = joined[:max_chars_per_patent]\n",
        "            aggregated[pid] = joined\n",
        "\n",
        "        return aggregated\n",
        "\n",
        "    except requests.HTTPError as e:\n",
        "        status = getattr(e.response, \"status_code\", \"?\")\n",
        "        text = getattr(e.response, \"text\", \"\")\n",
        "        print(f\"/g_claim HTTP {status}: {text[:300]}\")\n",
        "        return {}\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"/g_claim connection error: {e}\")\n",
        "        return {}\n",
        "\n",
        "# =========================\n",
        "# Semantic Ranking\n",
        "# =========================\n",
        "def load_st_model(name: str = \"all-MiniLM-L6-v2\", device: Optional[str] = None) -> SentenceTransformer:\n",
        "    if device is None:\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Loading SentenceTransformer '{name}' on device: {device}\")\n",
        "    return SentenceTransformer(name, device=device)\n",
        "\n",
        "def embed_texts(model: SentenceTransformer, texts: List[str], batch_size: int = 64) -> np.ndarray:\n",
        "    embs = model.encode(\n",
        "        texts,\n",
        "        batch_size=batch_size,\n",
        "        show_progress_bar=False,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "    return embs\n",
        "\n",
        "def cosine_sim_matrix(query_emb: np.ndarray, doc_embs: np.ndarray) -> np.ndarray:\n",
        "    return doc_embs @ query_emb   # normalized -> dot = cosine\n",
        "\n",
        "\n",
        "def semantic_rank_patents_by_claims(\n",
        "    search_text: str,\n",
        "    *,\n",
        "    model: Optional[SentenceTransformer] = None,\n",
        "    top_k: int = 50,\n",
        "    claim_rows_per_call: int = 1000,\n",
        "    max_claims_total: int = 3000,\n",
        "    max_chars_per_patent: int = 4000\n",
        ") -> Tuple[List[Tuple[str, str]], int]:\n",
        "    \"\"\"\n",
        "    1) Fetch claims w/ text from /g_claim\n",
        "    2) Embed query + aggregated claim_text\n",
        "    3) Rank by cosine similarity\n",
        "    4) Return top_k (patent_id, aggregated_claim_text) tuples and total count\n",
        "    \"\"\"\n",
        "    aggregated = fetch_claims_with_text(\n",
        "        search_text,\n",
        "        rows_per_call=claim_rows_per_call,\n",
        "        max_claims_total=max_claims_total,\n",
        "        max_chars_per_patent=max_chars_per_patent\n",
        "    )\n",
        "    total_aggregated_count = len(aggregated)\n",
        "    print(f\"Fetched and aggregated claims for {total_aggregated_count} patents.\")\n",
        "\n",
        "    if not aggregated:\n",
        "        return [], 0\n",
        "\n",
        "    model = model or load_st_model()\n",
        "    pids = list(aggregated.keys())\n",
        "    claim_texts = [aggregated[pid] for pid in pids]\n",
        "\n",
        "    query_emb = embed_texts(model, [search_text])[0]\n",
        "    doc_embs  = embed_texts(model, claim_texts)\n",
        "\n",
        "    sims = cosine_sim_matrix(query_emb, doc_embs)\n",
        "    order = np.argsort(-sims)\n",
        "    top_k = min(top_k, len(order))\n",
        "    top_idx = order[:top_k]\n",
        "\n",
        "    # Return list of (patent_id, claim_text) tuples\n",
        "    top_ranked_tuples = [(pids[i], claim_texts[i]) for i in top_idx]\n",
        "\n",
        "    return top_ranked_tuples, total_aggregated_count\n",
        "\n",
        "# =========================\n",
        "# NEW: LLM Selection based on Claims\n",
        "# =========================\n",
        "def llm_select_top_patents_from_claims(\n",
        "    query: str,\n",
        "    ranked_claims: List[Tuple[str, str]],\n",
        "    top_n: int = 2\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Asks the LLM to analyze a list of (patent_id, aggregated_claim_text)\n",
        "    and select the top_n most relevant patent_ids.\n",
        "    \"\"\"\n",
        "    print(f\"Sending {len(ranked_claims)} semantically-ranked claims to LLM for selection...\")\n",
        "\n",
        "    # Format for the prompt\n",
        "    claims_list_for_llm = [\n",
        "        {\"patent_id\": pid, \"aggregated_claim_text\": text}\n",
        "        for pid, text in ranked_claims\n",
        "    ]\n",
        "    claims_json_str = json.dumps(claims_list_for_llm, indent=2)\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a patent research analyst. Your task is to analyze a list of \"\n",
        "        \"semantically-ranked patents based on their aggregated claims and \"\n",
        "        \"select the *most* relevant ones based on the user's query. \"\n",
        "        \"You must return a JSON object containing a single key: 'top_patent_ids', \"\n",
        "        \"which is a list of the patent ID strings you selected.\"\n",
        "    )\n",
        "\n",
        "    user_prompt = (\n",
        "        f\"My query is: '{query}'.\\n\\n\"\n",
        "        f\"Here is a list of {len(ranked_claims)} patents, pre-ranked by semantic \"\n",
        "        \"similarity of their claims. Please analyze the 'aggregated_claim_text' \"\n",
        "        f\"for each and identify the {top_n} patent_ids that are *most* relevant \"\n",
        "        \"to my query.\\n\\n\"\n",
        "        f\"Patents to analyze:\\n{claims_json_str}\\n\\n\"\n",
        "        f\"Return a JSON object with a 'top_patent_ids' key containing a list \"\n",
        "        f\"of exactly {top_n} patent ID strings. For example: \"\n",
        "        f\"{json.dumps({'top_patent_ids': ['1234567', '7654321']})}\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        completion = OPENAI_CLIENT.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=messages,\n",
        "            temperature=0.1,\n",
        "            response_format={\"type\": \"json_object\"},\n",
        "        )\n",
        "        llm_response_json = completion.choices[0].message.content.strip()\n",
        "        llm_data = json.loads(llm_response_json)\n",
        "\n",
        "        if \"top_patent_ids\" not in llm_data or not isinstance(llm_data[\"top_patent_ids\"], list):\n",
        "            print(f\"LLM selection response was not in the expected format: {llm_response_json}\")\n",
        "            return []\n",
        "\n",
        "        selected_ids = [str(pid) for pid in llm_data[\"top_patent_ids\"]]\n",
        "        return selected_ids[:top_n] # Ensure we only return top_n\n",
        "\n",
        "    except (OpenAIError, json.JSONDecodeError, ValidationError) as e:\n",
        "        print(\"\\n--- Error during LLM claim-based selection ---\")\n",
        "        print(f\"Error: {e}\")\n",
        "        raw_output = \"No response\"\n",
        "        if \"llm_response_json\" in locals():\n",
        "            raw_output = llm_response_json\n",
        "        print(f\"Raw LLM Output:\\n{raw_output}\")\n",
        "        return []\n",
        "\n",
        "# =========================\n",
        "# Patent endpoint search (MODIFIED)\n",
        "# =========================\n",
        "def call_patentsview_search(\n",
        "    search_text: str,\n",
        "    *,\n",
        "    rows: int = 10,\n",
        "    publication_from: Optional[str] = None,\n",
        "    publication_to: Optional[str] = None,\n",
        "    claim_match_patent_ids: Optional[List[str]] = None,\n",
        "    search_by_text: bool = True # NEW parameter\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    core_query_parts = []\n",
        "\n",
        "    # Add text search clause ONLY if search_by_text is True\n",
        "    if search_by_text and search_text:\n",
        "        keywords = _extract_keywords(search_text)\n",
        "        text_value = _make_text_value(keywords) or search_text\n",
        "\n",
        "        title_clause = {\"_or\": [\n",
        "            {\"_text_phrase\": {\"patent_title\": search_text}},\n",
        "            {\"_text_all\": {\"patent_title\": text_value}},\n",
        "        ]}\n",
        "        abstract_clause = {\"_or\": [\n",
        "            {\"_text_phrase\": {\"patent_abstract\": search_text}},\n",
        "            {\"_text_all\": {\"patent_abstract\": text_value}},\n",
        "        ]}\n",
        "        title_abstract_clause = {\"_or\": [title_clause, abstract_clause]}\n",
        "        core_query_parts.append(title_abstract_clause)\n",
        "\n",
        "    # Add patent ID clause if provided\n",
        "    if claim_match_patent_ids:\n",
        "        core_query_parts.append({\"patent_id\": claim_match_patent_ids})\n",
        "\n",
        "    if not core_query_parts:\n",
        "        return {\"error\": True, \"message\": \"No search query or patent IDs provided.\"}\n",
        "\n",
        "    # Combine clauses with _or\n",
        "    core_query = {\"_or\": core_query_parts} if len(core_query_parts) > 1 else core_query_parts[0]\n",
        "\n",
        "    date_clauses = []\n",
        "    if publication_from:\n",
        "        date_clauses.append({\"_gte\": {\"patent_date\": publication_from}})\n",
        "    if publication_to:\n",
        "        date_clauses.append({\"_lte\": {\"patent_date\": publication_to}})\n",
        "\n",
        "    q = {\"_and\": [core_query] + date_clauses} if date_clauses else core_query\n",
        "\n",
        "    f = [\n",
        "        \"patent_id\",\n",
        "        \"patent_title\",\n",
        "        \"patent_date\",\n",
        "        \"patent_abstract\",\n",
        "        \"inventors.inventor_name_first\",\n",
        "        \"inventors.inventor_name_last\",\n",
        "        \"assignees.assignee_organization\",\n",
        "        \"assignees.assignee_first_name\",\n",
        "        \"assignees.assignee_last_name\",\n",
        "    ]\n",
        "    s = [{\"patent_date\": \"desc\"}]\n",
        "    o = {\"size\": min(rows, 1000)}\n",
        "    body = {\"q\": q, \"f\": f, \"s\": s, \"o\": o}\n",
        "\n",
        "    try:\n",
        "        resp = requests.post(\n",
        "            PATENT_ENDPOINT,\n",
        "            headers={**_base_headers(), \"Content-Type\": \"application/json\"},\n",
        "            data=json.dumps(body),\n",
        "            timeout=45,\n",
        "        )\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        if isinstance(data, dict) and data.get(\"error\"):\n",
        "            return {\"error\": True, \"message\": f\"PatentsView API error: {data}\"}\n",
        "        return data\n",
        "    except requests.HTTPError as e:\n",
        "        status = getattr(e.response, \"status_code\", \"?\")\n",
        "        return {\"error\": True, \"message\": f\"PatentsView HTTP {status}: {e.response.text if e.response else ''}\"}\n",
        "    except requests.RequestException as e:\n",
        "        return {\"error\": True, \"message\": f\"PatentsView connection error: {e}\"}\n",
        "\n",
        "\n",
        "def extract_patentsview_patent_summaries(api_response: Dict[str, Any]) -> List[Patent]:\n",
        "    candidates = api_response.get(\"patents\", [])\n",
        "    if not candidates:\n",
        "        return []\n",
        "\n",
        "    summaries: List[Patent] = []\n",
        "    for item in candidates:\n",
        "        inventor_list = []\n",
        "        for inv in item.get(\"inventors\", []):\n",
        "            first = inv.get(\"inventor_name_first\") or inv.get(\"inventor_first_name\", \"\")\n",
        "            last = inv.get(\"inventor_name_last\") or inv.get(\"inventor_last_name\", \"\")\n",
        "            name = f\"{first} {last}\".strip()\n",
        "            if name:\n",
        "                inventor_list.append(name)\n",
        "        inventor_str = \", \".join(inventor_list) if inventor_list else \"Unknown inventor\"\n",
        "\n",
        "        assignee_list = []\n",
        "        for ass in item.get(\"assignees\", []):\n",
        "            org = ass.get(\"assignee_organization\")\n",
        "            if org:\n",
        "                assignee_list.append(org.strip())\n",
        "            else:\n",
        "                first = ass.get(\"assignee_first_name\", \"\")\n",
        "                last = ass.get(\"assignee_last_name\", \"\")\n",
        "                name = f\"{first} {last}\".strip()\n",
        "                if name:\n",
        "                    assignee_list.append(name)\n",
        "        assignee_str = \", \".join(assignee_list) if assignee_list else \"Unknown assignee\"\n",
        "\n",
        "        patent_id = str(item.get(\"patent_id\", \"N/A\"))\n",
        "        title = str(item.get(\"patent_title\", \"No title available\"))\n",
        "        abstract = str(item.get(\"patent_abstract\", \"No snippet available.\"))\n",
        "        date = str(item.get(\"patent_date\", \"Unknown\"))\n",
        "\n",
        "        summaries.append(\n",
        "            Patent(\n",
        "                patent_number=patent_id,\n",
        "                application_number=\"N/A\",\n",
        "                title=title,\n",
        "                snippet=abstract,\n",
        "                publication_date=date,\n",
        "                inventor=inventor_str,\n",
        "                assignee=assignee_str,\n",
        "                status=\"Unknown status\",\n",
        "                patent_link=f\"https://patents.google.com/patent/US{patent_id}\",\n",
        "                pdf_link=None,\n",
        "                claims_snippet=None,\n",
        "                claims_summary=None,\n",
        "            )\n",
        "        )\n",
        "    return summaries\n",
        "\n",
        "\n",
        "def download_patents(patents: List[Patent], save_dir: str):\n",
        "    if not os.path.exists(save_dir):\n",
        "        try:\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "            print(f\"Created directory: {save_dir}\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error creating directory {save_dir}: {e}\")\n",
        "            return\n",
        "\n",
        "    for patent in patents:\n",
        "        if not patent.pdf_link or not patent.pdf_link.startswith(\"http\"):\n",
        "            print(f\"Skipping {patent.patent_number}: No valid PDF link found.\")\n",
        "            continue\n",
        "        try:\n",
        "            print(f\"Downloading PDF for {patent.patent_number}...\")\n",
        "            pdf_response = requests.get(patent.pdf_link, timeout=20)\n",
        "            pdf_response.raise_for_status()\n",
        "            safe_filename = re.sub(r\"[^\\w\\.-]\", \"_\", patent.patent_number) + \".pdf\"\n",
        "            save_path = os.path.join(save_dir, safe_filename)\n",
        "            with open(save_path, \"wb\") as f:\n",
        "                f.write(pdf_response.content)\n",
        "            print(f\"Successfully saved: {save_path}\")\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Failed to download {patent.patent_number} from {patent.pdf_link}: {e}\")\n",
        "# =========================\n",
        "# Main Workflow (REFACTORED)\n",
        "# =========================\n",
        "def search_and_summarize_patents(\n",
        "    query: str,\n",
        "    *,\n",
        "    publication_from: Optional[str] = None,\n",
        "    publication_to: Optional[str] = None,\n",
        "    top_k_claims_for_llm_ranking: int = 50,\n",
        "    top_n_final_selection: int = 2\n",
        ") -> Optional[LLMSummary]:\n",
        "    \"\"\"\n",
        "    Workflow (REVISED):\n",
        "      1) /g_claim: retrieve *matching claim snippets*\n",
        "      2) SentenceTransformer: rank patents by snippets -> top 50\n",
        "      3) PatentsView: *Always* use fetch_patentsview_claims_by_id() to get *full claims text*\n",
        "      4) SerpApi: (If enabled) *Only* try to fetch the pdf_link\n",
        "      5) LLM: analyzes top 50 *full claims* -> selects top 2 patent_ids\n",
        "      ...rest of workflow...\n",
        "    \"\"\"\n",
        "    print(\"Step 1: Fetch + rank claims semantically (by snippet)...\")\n",
        "    top_ranked_claims, total_aggregated_count = semantic_rank_patents_by_claims(\n",
        "        query,\n",
        "        top_k=top_k_claims_for_llm_ranking\n",
        "    )\n",
        "\n",
        "    if not top_ranked_claims:\n",
        "        print(f\"Sorry, I couldn't find any patents or applications matching '{query}'.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Found {total_aggregated_count} patents with matching claims. Enriching top {len(top_ranked_claims)}...\")\n",
        "\n",
        "    # --- MODIFIED: Enrichment Step ---\n",
        "    enriched_claims_data: Dict[str, Tuple[str, Optional[str], Optional[str]]] = {}\n",
        "    claims_to_pass_to_llm: List[Tuple[str, str]] = []\n",
        "\n",
        "    print(f\"Step 2: Enriching top {len(top_ranked_claims)} claims (PatentsView + SerpApi for PDF)...\")\n",
        "    for pid, matching_snippet in top_ranked_claims:\n",
        "        pdf_link: Optional[str] = None\n",
        "        full_claims_text: Optional[str] = None\n",
        "\n",
        "        # --- 1. Always get claims from PatentsView (as requested) ---\n",
        "        #print(f\"Fetching claims for {pid} from PatentsView /g_claim...\")\n",
        "        full_claims_text = fetch_patentsview_claims_by_id(pid)\n",
        "\n",
        "        #if full_claims_text:\n",
        "        #    print(f\"PatentsView success: Found {len(full_claims_text)} chars of claims for {pid}\")\n",
        "        #else:\n",
        "        #    print(f\"PatentsView failed to find claims for {pid}\")\n",
        "\n",
        "        # --- 2. Get PDF link if possible (SerpApi's only remaining job) ---\n",
        "        if SERPAPI_API_KEY_SET:\n",
        "            # We only care about the pdf_link from SerpApi now\n",
        "            # We ignore the claims_text it returns\n",
        "            pdf_link, _ = fetch_serpapi_details(pid)\n",
        "            #if pdf_link:\n",
        "                 #print(f\"SerpApi success: Found PDF for {pid}\")\n",
        "            #else:\n",
        "             #    print(f\"SerpApi could not find PDF for {pid}\")\n",
        "\n",
        "        # --- 3. Store results ---\n",
        "        # Use full_claims_text if we got it, otherwise fall back to the original snippet\n",
        "        text_for_llm = full_claims_text if full_claims_text else matching_snippet\n",
        "\n",
        "        claims_to_pass_to_llm.append((pid, text_for_llm))\n",
        "        # Store everything we found\n",
        "        enriched_claims_data[pid] = (matching_snippet, pdf_link, full_claims_text)\n",
        "\n",
        "    print(\"Enrichment complete.\")\n",
        "    # --- END MODIFIED ---\n",
        "\n",
        "\n",
        "    print(\"Step 3: LLM selecting top patents based on aggregated (or enriched) claims...\")\n",
        "\n",
        "    print(\"Passing claims to LLM (snippets):\", [(pid, text[:150] + \"...\") for pid, text in claims_to_pass_to_llm[:10]])\n",
        "\n",
        "    llm_selected_ids = llm_select_top_patents_from_claims(\n",
        "        query,\n",
        "        claims_to_pass_to_llm,\n",
        "        top_n=top_n_final_selection\n",
        "    )\n",
        "\n",
        "    if not llm_selected_ids:\n",
        "        print(\"LLM failed to select any patents from the claims list.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"LLM selected top IDs: {llm_selected_ids}\")\n",
        "\n",
        "    print(\"Step 4: Fetching full patent details for LLM-selected IDs...\")\n",
        "    # ... (rest of your function remains identical) ...\n",
        "    raw = call_patentsview_search(\n",
        "        query,\n",
        "        rows=len(llm_selected_ids),\n",
        "        publication_from=publication_from,\n",
        "        publication_to=publication_to,\n",
        "        claim_match_patent_ids=llm_selected_ids,\n",
        "        search_by_text=False\n",
        "    )\n",
        "\n",
        "    if raw.get(\"error\"):\n",
        "        print(f\"Error from PatentsView: {raw['message']}\")\n",
        "        return None\n",
        "\n",
        "    final_patents = extract_patentsview_patent_summaries(raw)\n",
        "\n",
        "    if not final_patents:\n",
        "        print(f\"Could not fetch details for LLM-selected patents: {llm_selected_ids}\")\n",
        "        return None\n",
        "\n",
        "    # Inject stored PDF/Claims data into the final Patent objects\n",
        "    for patent in final_patents:\n",
        "        if patent.patent_number in enriched_claims_data:\n",
        "            original_snippet, pdf_link, full_claims = enriched_claims_data[patent.patent_number]\n",
        "            # Prioritize SerpApi PDF link if it exists\n",
        "            if pdf_link:\n",
        "                patent.pdf_link = pdf_link\n",
        "            # Use full claims if we have them, otherwise fall back to original snippet\n",
        "            patent.claims_snippet = full_claims if full_claims else original_snippet\n",
        "\n",
        "    # Re-order patents to match LLM's selection order\n",
        "    final_patents_map = {p.patent_number: p for p in final_patents}\n",
        "    ordered_final_patents = [final_patents_map[pid] for pid in llm_selected_ids if pid in final_patents_map]\n",
        "\n",
        "    print(\"Step 5: Generating final summary with LLM (based on selected patents)...\")\n",
        "    # ... (rest of your function remains identical) ...\n",
        "    summaries_list_of_dicts = [p.model_dump() for p in ordered_final_patents]\n",
        "    summaries_str = json.dumps(summaries_list_of_dicts, indent=2)\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a patent research assistant. Your task is to analyze a *final, pre-selected* \"\n",
        "        \"list of patents and return a JSON object with two keys: \"\n",
        "        \"1. `summary_text`: A concise, natural-language summary based on the title, \"\n",
        "        \"   abstract, and importantly, the `claims_snippet`. \"\n",
        "        \"   This summary must explicitly state the total number of patents \"\n",
        "        \"   found in the *initial* claim search. \"\n",
        "        \"2. `top_2_relevant_patents`: The JSON list of the patent objects I provided.\"\n",
        "    )\n",
        "\n",
        "    user_prompt = (\n",
        "        f\"My query is: '{query}'.\\n\"\n",
        "        f\"We found {total_aggregated_count} total patents in an initial claim search. \"\n",
        "        \"After a multi-step process (semantic ranking + LLM selection), we \"\n",
        "        f\"identified these {len(ordered_final_patents)} as the most relevant.\\n\\n\"\n",
        "        f\"Here are the full details for these selected patents (including `claims_snippet` if found):\\n\"\n",
        "        f\"{summaries_str}\\n\\n\"\n",
        "        \"Please generate a summary for these patents, paying close attention to the `claims_snippet`. \"\n",
        "        f\"In your summary, you must state that {total_aggregated_count} total patents \"\n",
        "        \"were found in the initial search. \"\n",
        "        \"Finally, return a single JSON object containing both the `summary_text` \"\n",
        "        \"and the `top_2_relevant_patents` list (which is just the list I provided you).\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        completion = OPENAI_CLIENT.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=messages,\n",
        "            temperature=0.2,\n",
        "            response_format={\"type\": \"json_object\"},\n",
        "        )\n",
        "        llm_response_json = completion.choices[0].message.content.strip()\n",
        "        llm_data = json.loads(llm_response_json)\n",
        "\n",
        "        llm_data['top_2_relevant_patents'] = ordered_final_patents\n",
        "        validated_response = LLMSummary(**llm_data)\n",
        "\n",
        "        print(\"PatentsView claims enrichment is complete.\")\n",
        "\n",
        "        return validated_response\n",
        "\n",
        "    except (OpenAIError, json.JSONDecodeError, ValidationError) as e:\n",
        "        print(\"\\n--- Error parsing FINAL LLM summary response ---\")\n",
        "        print(f\"Error: {e}\")\n",
        "        raw_output = \"No response\"\n",
        "        if \"llm_response_json\" in locals():\n",
        "            raw_output = llm_response_json\n",
        "        print(f\"Raw LLM Output:\\n{raw_output}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Main\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    SAVE_DIRECTORY = \"./fetched_patents\"\n",
        "\n",
        "    query = \"a flying car that can transform between driving and flying modes\"\n",
        "    print(f\"--- Running Service 1 for query: '{query}' (PatentsView + ST + SerpApi) ---\")\n",
        "\n",
        "    llm_summary_object = search_and_summarize_patents(\n",
        "        query,\n",
        "        top_k_claims_for_llm_ranking=8, # How many claims to send to LLM for ranking the less the better for the lmm\n",
        "        top_n_final_selection=2          # How many patents the LLM should select\n",
        "    )\n",
        "\n",
        "    if llm_summary_object:\n",
        "        print(\"\\n--- LLM Summary Text ---\")\n",
        "        print(llm_summary_object.summary_text)\n",
        "        print(\"\\n--- LLM Selected Top 2 Patents (Pydantic Objects) ---\")\n",
        "        for i, patent in enumerate(llm_summary_object.top_2_relevant_patents):\n",
        "            print(f\"\\n--- Top {i + 1} Relevant Patent ---\")\n",
        "            print(patent.model_dump_json(indent=2))\n",
        "        print(\"\\n--- PDF Download ---\")\n",
        "        download_patents(llm_summary_object.top_2_relevant_patents, SAVE_DIRECTORY)\n",
        "    else:\n",
        "        print(\"Search failed to produce a valid summary object.\")"
      ],
      "metadata": {
        "id": "nmyCLaWqmU7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7827a382-109e-4464-ade3-dea151cc489e"
      },
      "id": "nmyCLaWqmU7P",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SerpApi library not found. Please run: pip install google-search-results\n",
            "--- Running Service 1 for query: 'a flying car that can transform between driving and flying modes' (PatentsView + ST + SerpApi) ---\n",
            "Step 1: Fetch + rank claims semantically (by snippet)...\n",
            "Fetched and aggregated claims for 372 patents.\n",
            "Loading SentenceTransformer 'all-MiniLM-L6-v2' on device: cpu\n",
            "Found 372 patents with matching claims. Enriching top 8...\n",
            "Step 2: Enriching top 8 claims (PatentsView + SerpApi for PDF)...\n",
            "Enrichment complete.\n",
            "Step 3: LLM selecting top patents based on aggregated (or enriched) claims...\n",
            "Passing claims to LLM (snippets): [('11214275', '1. A vehicle comprising: a steering wheel; one or more vehicle drive systems comprising at least a vehicle suspension system; one or more driving mode...'), ('11214277', '1. A control device for a vehicle, capable of switching between an automated driving mode in which a driving force of a vehicle that has a power sourc...'), ('11214368', '1. A system for operating flying machines, comprising: a control system configured to: store role information for the flying machines; and communicate...'), ('11214357', '1. A wing for an aircraft, comprising: a fixed wing, a foldable wing tip portion rotatably attached to the fixed wing, an actuation unit for rotating ...'), ('11214292', '1. A control method to control a car ( 1 ) comprising the steps of: determining a position of a joystick ( 7 ), which is designed to be grabbed by a h...'), ('11214276', '1. An operating method for an emergency vehicle, which emergency vehicle is provided with a vehicle body, a drive unit, having at least one drive moto...'), ('11214329', '1. A telescoping and foldable electric vehicle, comprising a front frame ( 1 ), a rear frame ( 2 ), a power supply and a controller, further comprisin...'), ('11214152', '1. A working device connected to a traveling vehicle having a prime mover and configured to perform an agricultural work, comprising: a working portio...')]\n",
            "Sending 8 semantically-ranked claims to LLM for selection...\n",
            "LLM selected top IDs: ['11214368', '11214277']\n",
            "Step 4: Fetching full patent details for LLM-selected IDs...\n",
            "Step 5: Generating final summary with LLM (based on selected patents)...\n",
            "PatentsView claims enrichment is complete.\n",
            "\n",
            "--- LLM Summary Text ---\n",
            "In an initial search for patents related to 'a flying car that can transform between driving and flying modes', a total of 372 patents were found. The two most relevant patents include a system for charging and operating flying machines, which details a control system for managing multiple flying machines and their roles, and a control device for vehicles that allows switching between automated and manual driving modes, enhancing the vehicle's adaptability in various driving conditions.\n",
            "\n",
            "--- LLM Selected Top 2 Patents (Pydantic Objects) ---\n",
            "\n",
            "--- Top 1 Relevant Patent ---\n",
            "{\n",
            "  \"patent_number\": \"11214368\",\n",
            "  \"application_number\": \"N/A\",\n",
            "  \"title\": \"Systems and methods for charging, transporting, and operating flying machines\",\n",
            "  \"snippet\": \"A flying machine storage container is provided that comprises multiple charging stations and a clamping mechanism. The clamping mechanism is configured to secure flying machines in the charging stations and securely close charging circuits between the storage container and the flying machines. A system for launching flying machines is also provided. The system comprises two regions and a transition region between the two regions. The two regions each constrain the positioning of a flying machine and the transition region enables a flying machine to move from the first region to the second region to reach an exit. A flying machine having sufficient performance capabilities will be able to successfully launch. Centralized and decentralized communication architectures are also provided for communicating data between a central control system, multiple storage containers, and multiple stored flying machines stored at each of the storage containers.\",\n",
            "  \"publication_date\": \"2022-01-04\",\n",
            "  \"inventor\": \"Raffaello D'Andrea, Philipp Reist, Mark W. Mueller, Markus Hehn, Markus Waibel, Federico Augugliaro\",\n",
            "  \"assignee\": \"Verity AG\",\n",
            "  \"status\": \"Unknown status\",\n",
            "  \"patent_link\": \"https://patents.google.com/patent/US11214368\",\n",
            "  \"pdf_link\": null,\n",
            "  \"claims_snippet\": \"1. A system for operating flying machines, comprising: a control system configured to: store role information for the flying machines; and communicate the role information; a first flying machine storage container configured to: store a first subset of the flying machines; receive a first set of role information from the control system for the first subset of the flying machines; and communicate the first set of role information to the flying machines in the first subset of the flying machines; and a second flying machine storage container configured to: store a second subset of the flying machines; receive a second set of role information from the control system for the second subset of the flying machines; and communicate the second set of role information to the flying machines in the second subset of the flying machines. 2. The system of claim 1 , wherein the control system is configured to communicate the role information using a wired communication path. 3. The system of claim 1 , wherein the first flying machine storage container is configured to communicate the first set of role information to the flying machines in the first subset of the flying machines using a wired communication path. 4. The system of claim 1 , wherein the control system is configured to communicate the role information using a wireless communication path. 5. The system of claim 1 , wherein the first flying machine storage container is configured to communicate the first set of role information to the flying machines in the first subset of the flying machines using a wireless communication path. 6. The system of claim 1 , wherein the first set of role information comprises a subset of the role information stored at the control system for the first subset of the flying machines. 7. The system of claim 1 , wherein the first flying machine storage container is configured to individually communicate with each of the first subset of the flying machines. 8. The system of claim 1 , wherein the role information for the flying machines stored at the control system comprises a plurality of specific roles for the flying machines. 9. The system of claim 1 , wherein the role information for the flying machines stored at the control system comprises flight path information for the flying machines to perform a choreographed performance. 10. The system of claim 1 , wherein the first set of role information comprises a plurality of specific roles and wherein the first flying machine storage container is configured to transmit a specific role to each flying machine in the first subset based on a position of the flying machine in the first flying machine storage container. 11. The system of claim 1 , wherein the first flying machine storage container comprises a localization unit configured to determine the location of the first flying machine storage container and wherein the first flying machine storage container is configured to communicate its location to the control system. 12. The system of claim 11 , wherein the control system generates the first subset of role information based on the location of the first flying machine storage container. 13. The system of claim 1 , wherein the first flying machine storage container comprises a localization unit configured to determine the location of the first flying machine storage container and wherein the first flying machine storage container is configured to receive a set of role information from the control system and to determine whether said received set is the first set based on the determined location. 14. The system of claim 1 , wherein the first flying machine storage container is configured to: identify which flying machines are stored at the first flying machine storage container; and communicate the identity of the stored flying machines to the control system. 15. The system of claim 1 , wherein the first flying machine storage container is configured to: determine the number of flying machines stored in the first flying machine storage container; and communicate the number to the control system. 16. The system of claim 1 , wherein the first flying machine storage container adjusts the role information based on the identity of the stored flying machines or the number of stored flying machines. 17. The system of claim 1 , wherein the first flying machine storage container is configured to: release the first subset of flying machines one at a time from an exit; and communicate a specific role to each flying machine of the first subset one at a time prior to the flying machine being released from the exit. 18. A method for programming flying machines, comprising: determining, using a control system, a first set of role information to be transmitted to a first flying machine storage container; transmitting, using the control system, the first set of role information to the first flying machine storage container; receiving, using the first flying machine storage container, the first set of role information; transmitting, using the first flying machine storage container, the first set of role information to a first plurality of flying machines stored in the first flying machine storage container; determining, using a control system, a second set of role information to be transmitted to a second flying machine storage container; transmitting, using the control system, the second set of role information to the second flying machine storage container; receiving, using the second flying machine storage container, the second set of role information; and transmitting, using the second flying machine storage container, the second set of role information to a second plurality of flying machines stored in the second flying machine storage container. 19. The method of claim 18 , wherein the first set of role information comprises a plurality of specific roles and wherein transmitting the first set of role information to the first plurality of flying machines comprises transmitting a specific role to each flying machine in the first plurality of flying machines based on a position of the flying machine in the first flying machine storage container. 20. The method of claim 18 , further comprising: determining, using a localization unit of the first flying machine storage container, the location of the first flying machine storage container; and transmitting the determined location to the control system. 21. The method of claim 18 , further comprising: identifying, using the first flying machine storage container, which flying machines are stored in the first flying machine storage container.\",\n",
            "  \"claims_summary\": null\n",
            "}\n",
            "\n",
            "--- Top 2 Relevant Patent ---\n",
            "{\n",
            "  \"patent_number\": \"11214277\",\n",
            "  \"application_number\": \"N/A\",\n",
            "  \"title\": \"Control device for vehicle\",\n",
            "  \"snippet\": \"A control device for a vehicle capable of switching between an automated driving mode in which driving force of a vehicle having a transmission is automatically controlled and a manual driving mode in which the driving force of the vehicle is controlled on the basis of a driver's operation on the vehicle includes: an operation element to which the driver's operation is input; and a travel control unit that outputs a command value for selecting a gear range of the transmission. The travel control unit selects which of ordinary gear change control and gear change restricting control is to be performed on the basis of an operation performed on the operation element when there is an automated driving release request in which the automated driving mode is released and the automated driving mode is switched to the manual driving mode during traveling of the vehicle in the automated driving mode.\",\n",
            "  \"publication_date\": \"2022-01-04\",\n",
            "  \"inventor\": \"Hisashi Ishikawa, Takashi Adachi, Kentaro Arai, Masayuki Sadakiyo, Tomoyuki Noguchi\",\n",
            "  \"assignee\": \"HONDA MOTOR CO., LTD.\",\n",
            "  \"status\": \"Unknown status\",\n",
            "  \"patent_link\": \"https://patents.google.com/patent/US11214277\",\n",
            "  \"pdf_link\": null,\n",
            "  \"claims_snippet\": \"1. A control device for a vehicle, capable of switching between an automated driving mode in which a driving force of a vehicle that has a power source and a transmission that performs a gear change for rotation using a power delivered from the power source is automatically controlled and a manual driving mode in which the driving force of the vehicle is controlled on a basis of a driver's operation on the vehicle, the control device comprising: an operation element comprising an accelerator pedal to which the driver's operation is input in order to control the driving force of the vehicle; a memory; and a processor configured to perform: a switching control for switching between the automated driving mode and the manual driving mode; and a travel control; wherein in the travel control, the processor is configured to output a travel control command value including a command value for selecting a gear range of the transmission, wherein in the travel control the processor is further configured to perform: deciding the gear range of the transmission on a basis of the driving force of the vehicle, and selecting an ordinary gear change control or a gear change restricting control that restricts a change in gear range as compared with the ordinary gear change control, and selecting which of the ordinary gear change control and the gear change restricting control is to be performed on a basis of an operation performed on the accelerator pedal of the operation element when there is an automated driving release request in which the automated driving mode is released and the automated driving mode is switched to the manual driving mode during traveling of the vehicle in the automated driving mode, wherein when the automated driving release request in which the automated driving mode is released and the automated driving mode is switched to the manual driving mode is provided during traveling of the vehicle in the automated driving mode, the processor is configured to perform a driving force shifting control for gradually shifting the driving force of the vehicle from the driving force of the vehicle in the automated driving mode to the driving force that the driver requests in the manual driving mode. 2. The control device for a vehicle according to claim 1 , further comprising: a plurality of shift maps that are stored in the memory and for deciding the gear range of the transmission, and wherein in the travel control the processor is further configured to perform: uses an ordinary shift map stored in the memory in a case in which the ordinary gear change control is performed, and uses a shift map that is stored in the memory and used for restricting the change in gear range as compared with the ordinary shift map in a case in which the gear change restricting control is performed. 3. The control device for a vehicle according to claim 1 , wherein the gear change restricting control includes a control for restricting the change in gear range by expanding a range of the driving force that uses the transmission range when the automated driving release request is provided as compared with an ordinary range. 4. The control device for a vehicle according to claim 1 , wherein the gear change restricting control includes a control for maintaining the gear range for a predetermined period of time when the automated driving release request is provided. 5. The control device for a vehicle according to claim 4 , wherein a length of the predetermined period of time is decided on a basis of the operation performed on the operation element. 6. The control device for a vehicle according to claim 5 , wherein the predetermined period of time is set to be short in a case in which no operation is performed on the operation element, and the predetermined period of time is set to be long in a case in which an operation is performed on the operation element. 7. The control device for a vehicle according to claim 1 , wherein a low-speed following travel mode in which the vehicle follows a preceding vehicle in a low-speed region is provided, the automated driving release request is input from the vehicle or the driver, and in a case in which the automated driving release request has been input from the vehicle, and in a case in which the driving force of the vehicle in the low-speed following travel mode is not able to be calculated in the travel control, the processor is configured to perform a control for restricting the change in gear range by expanding the range of the driving force that uses the gear range when the automated driving release request is provided as compared with an ordinary range in the gear change restricting control. 8. The control device for a vehicle according to claim 1 , wherein a low-speed following travel mode in which the vehicle follows a preceding vehicle in a low-speed region is provided, the automated driving release request is input from the vehicle or the driver, and in a case in which the automated driving release request has been input from the vehicle, and in a case in which the driving force of the vehicle in the low-speed following travel mode is not able to be calculated in the travel control, the processor is configured to perform a control for maintaining the gear range for a predetermined period of time when the automated driving release request is provided in the gear change restricting control.\",\n",
            "  \"claims_summary\": null\n",
            "}\n",
            "\n",
            "--- PDF Download ---\n",
            "Skipping 11214368: No valid PDF link found.\n",
            "Skipping 11214277: No valid PDF link found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Service 2: semantically compare the uploaded innovation with the top2 patents\n",
        "added pytesseract and pdf2image to enviroment. This let the user upload a pdf and it is compared semantically to the top 2 fetched patents pdfs. sometimes those pdf needs ocr to be read since even text are really not readable by pypdf but adding ocr takes a lot of time.\n",
        "but this took a lot of time! ON colab it was working fine (maybe bacause my documents were mr). I re run the\n",
        "So i took the pdf from the user and used\n",
        "\n",
        "I changed it to make sure that the users query is patentable."
      ],
      "metadata": {
        "id": "49aQM7SdNLg8"
      },
      "id": "49aQM7SdNLg8"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3P6PjAbGOZwB",
        "outputId": "88f795f2-83a7-45da-fd3e-3f8cd796f843"
      },
      "id": "3P6PjAbGOZwB",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.3.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.10)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.28.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.4)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.3.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=17de9c459464594e35af9068893940042c5d8c36ae2792a871f7c29e188b7e1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.3.4 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "opentelemetry",
                  "urllib3"
                ]
              },
              "id": "5b90ac5d38d24cfe9e688eafe3d5eeb1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eny1D6NqObvE",
        "outputId": "71033442-ce40-499a-972d-2445e9a708a0"
      },
      "id": "Eny1D6NqObvE",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (11.3.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGofqZb3Oeb1",
        "outputId": "47e722f8-3217-44bf-8cd0-336f64c18f1a"
      },
      "id": "vGofqZb3Oeb1",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pdf2image) (11.3.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pa4ECnWhOZGE"
      },
      "id": "pa4ECnWhOZGE"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from openai import OpenAI, OpenAIError\n",
        "from typing import Any, Dict, List, Optional\n",
        "import chromadb\n",
        "\n",
        "# --- PDF Parsing Imports ---\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "from pypdf import PdfReader\n",
        "\n",
        "# --- OpenAI Client Initialization ---\n",
        "try:\n",
        "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "    OPENAI_API_KEY_SET = bool(os.environ.get(\"OPENAI_API_KEY\"))\n",
        "except TypeError:\n",
        "    client = None\n",
        "    OPENAI_API_KEY_SET = False\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# PDF PARSING HELPERS (From Your Prompt)\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "def extract_text_with_pypdf(pdf_path: str) -> str:\n",
        "    \"\"\"\n",
        "    First attempt to extract text from the PDF using pypdf.\n",
        "    Returns the extracted text (may be empty string if none found).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        all_text = []\n",
        "\n",
        "        for i, page in enumerate(reader.pages):\n",
        "            page_text = page.extract_text() or \"\"  # pypdf may return None\n",
        "            if page_text.strip():\n",
        "                all_text.append(f\"--- Page {i + 1} (pypdf) ---\\n{page_text}\\n\")\n",
        "\n",
        "        return \"\\n\".join(all_text).strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"pypdf extraction failed: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def ocr_pdf_to_text(pdf_path: str) -> (str, str):\n",
        "    \"\"\"\n",
        "    Extracts text from an image-based PDF using OCR.\n",
        "    Returns (text, error_message) tuple.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(pdf_path):\n",
        "        return None, f\"Error: File not found at path: {pdf_path}\"\n",
        "\n",
        "    print(f\"Starting OCR process for: {pdf_path}\")\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path)\n",
        "        all_text = \"\"\n",
        "\n",
        "        for i, page_image in enumerate(images):\n",
        "            print(f\"Processing Page {i + 1} (OCR)...\")\n",
        "            text = pytesseract.image_to_string(page_image)\n",
        "            all_text += f\"--- Page {i + 1} (OCR) ---\\n\"\n",
        "            all_text += text + \"\\n\\n\"\n",
        "\n",
        "        if not all_text.strip():\n",
        "            return None, \"Error: OCR completed but returned no text.\"\n",
        "\n",
        "        return all_text.strip(), None\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"An error occurred during the OCR process: {e}\"\n",
        "\n",
        "\n",
        "def pdf_to_text_with_fallback(pdf_path: str) -> (str, str):\n",
        "    \"\"\"\n",
        "    Try to extract text using pypdf first.\n",
        "    If no text is found, fall back to OCR.\n",
        "    Returns (text, error_message) tuple.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(pdf_path):\n",
        "        return None, f\"Error: File not found at path: {pdf_path}\"\n",
        "\n",
        "    print(f\"Attempting text extraction with pypdf for: {pdf_path}\")\n",
        "    text_pypdf = extract_text_with_pypdf(pdf_path)\n",
        "\n",
        "    if text_pypdf and text_pypdf.strip():\n",
        "        print(\"Text successfully extracted with pypdf. Skipping OCR.\")\n",
        "        return text_pypdf, None\n",
        "\n",
        "    print(f\"No extractable text found with pypdf for {os.path.basename(pdf_path)}. Falling back to OCR...\")\n",
        "    return ocr_pdf_to_text(pdf_path)\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# SERVICE 2: CHROMA & SEMANTIC FUNCTIONS\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "def chunk_text(text: str) -> List[str]:\n",
        "    \"\"\"Splits text into paragraphs for embedding.\"\"\"\n",
        "    chunks = re.split(r'\\n\\s*\\n', text)\n",
        "    return [chunk.strip() for chunk in chunks if chunk.strip()]\n",
        "\n",
        "def get_embedding(text: str):\n",
        "    \"\"\"Use OpenAI embeddings for semantic indexing.\"\"\"\n",
        "    if not client:\n",
        "        raise ValueError(\"OpenAI client is not initialized.\")\n",
        "    emb = client.embeddings.create(\n",
        "        input=text,\n",
        "        model=\"text-embedding-3-small\"\n",
        "    )\n",
        "    return emb.data[0].embedding\n",
        "\n",
        "def init_collection(path=\"chroma_patent_store\", name=\"patent_comparison\"):\n",
        "    \"\"\"\n",
        "    Creates a persistent Chroma client and gets/creates the collection.\n",
        "    \"\"\"\n",
        "    chroma_client = chromadb.PersistentClient(path=path)\n",
        "    collection = chroma_client.get_or_create_collection(name=name)\n",
        "    print(f\"[Service 2] ChromaDB collection '{name}' loaded from path '{path}'.\")\n",
        "    return collection\n",
        "\n",
        "def populate_collection(collection, patent_folder_path: str):\n",
        "    \"\"\"\n",
        "    Finds PDFs in the folder, extracts text (with fallback), chunks, and adds to Chroma.\n",
        "    \"\"\"\n",
        "    collection.delete(where={\"source_patent\": {\"$ne\": \"dummy\"}})\n",
        "    print(\"[Service 2] Cleared old patent data from ChromaDB.\")\n",
        "\n",
        "    pdf_files = [f for f in os.listdir(patent_folder_path) if f.endswith(\".pdf\")]\n",
        "    if not pdf_files:\n",
        "        print(f\"No .pdf files found in {patent_folder_path}\")\n",
        "        return False\n",
        "\n",
        "    print(f\"Found {len(pdf_files)} patents to process in {patent_folder_path}\")\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        full_path = os.path.join(patent_folder_path, pdf_file)\n",
        "\n",
        "        # --- MODIFIED: Uses your pdf_to_text_with_fallback function ---\n",
        "        print(f\"\\n[Service 2] Processing patent file: {pdf_file}...\")\n",
        "        text, error = pdf_to_text_with_fallback(full_path)\n",
        "\n",
        "        if error:\n",
        "            print(f\"Skipping {pdf_file}: {error}\")\n",
        "            continue\n",
        "\n",
        "        chunks = chunk_text(text)\n",
        "        if not chunks:\n",
        "            print(f\"Skipping {pdf_file}: No text chunks found after processing.\")\n",
        "            continue\n",
        "\n",
        "        chunk_ids = [f\"{pdf_file}_chunk_{i}\" for i in range(len(chunks))]\n",
        "        metadatas = [{\"source_patent\": pdf_file} for _ in chunks]\n",
        "\n",
        "        try:\n",
        "            embeddings = [get_embedding(c) for c in chunks]\n",
        "            collection.add(\n",
        "                documents=chunks,\n",
        "                embeddings=embeddings,\n",
        "                ids=chunk_ids,\n",
        "                metadatas=metadatas\n",
        "            )\n",
        "            print(f\"[Service 2] Added {len(chunks)} chunks for {pdf_file} to collection.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error adding {pdf_file} to Chroma: {e}\")\n",
        "\n",
        "    return True\n",
        "\n",
        "def run_semantic_comparison(collection, user_pdf_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Performs semantic comparison and uses OpenAI to summarize.\n",
        "    \"\"\"\n",
        "    if not client:\n",
        "        return \"Error: OpenAI client not set for summarization.\"\n",
        "\n",
        "    # 1. Parse the user's \"query\" PDF using the robust fallback method\n",
        "    print(f\"\\n[Service 2] Parsing user PDF: {user_pdf_path}\")\n",
        "\n",
        "    # --- Uses your new pdf_to_text_with_fallback function ---\n",
        "    query_text, error = pdf_to_text_with_fallback(user_pdf_path)\n",
        "\n",
        "    if error:\n",
        "        return error\n",
        "\n",
        "    query_chunks = chunk_text(query_text)\n",
        "    if not query_chunks:\n",
        "        return \"Error: User PDF contains no text to query with.\"\n",
        "\n",
        "    # 2. Run semantic search for each chunk\n",
        "    print(f\"[Service 2] Querying ChromaDB with {len(query_chunks)} chunks from user PDF...\")\n",
        "    all_results = {} # To store distances for each patent\n",
        "\n",
        "    for i, chunk in enumerate(query_chunks):\n",
        "        try:\n",
        "            query_emb = get_embedding(chunk)\n",
        "            results = collection.query(\n",
        "                query_embeddings=[query_emb],\n",
        "                n_results=5\n",
        "            )\n",
        "\n",
        "            for dist, meta in zip(results['distances'][0], results['metadatas'][0]):\n",
        "                patent_id = meta['source_patent']\n",
        "                if patent_id not in all_results:\n",
        "                    all_results[patent_id] = []\n",
        "                all_results[patent_id].append(dist)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Error querying for chunk {i}: {e}\")\n",
        "\n",
        "    if not all_results:\n",
        "        return \"No semantic matches found in ChromaDB for the user's PDF.\"\n",
        "\n",
        "    # 3. Aggregate scores\n",
        "    final_scores = []\n",
        "    for patent_id, distances in all_results.items():\n",
        "        avg_distance = sum(distances) / len(distances)\n",
        "        final_scores.append({\n",
        "            \"patent_file\": patent_id,\n",
        "            \"average_similarity_score\": avg_distance,\n",
        "            \"matching_chunks\": len(distances)\n",
        "        })\n",
        "\n",
        "    final_scores.sort(key=lambda x: x['average_similarity_score'])\n",
        "\n",
        "    # 4. Ask the LLM to summarize the findings\n",
        "    prompt = (\n",
        "        f\"You are a helpful assistant. I have semantically compared my document ('{os.path.basename(user_pdf_path)}') \"\n",
        "        f\"against patent PDFs. The analysis resulted in the following similarity scores. \"\n",
        "        f\"A lower 'average_similarity_score' means the documents are MORE similar.\\n\\n\"\n",
        "        f\"Comparison Results:\\n{json.dumps(final_scores, indent=2)}\\n\\n\"\n",
        "        f\"Question: Based on these scores, which patent is more relevant to my document and why?\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        answer = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You summarize semantic comparison results clearly and concisely.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.5\n",
        "        )\n",
        "        return answer.choices[0].message.content.strip()\n",
        "    except OpenAIError as e:\n",
        "        return f\"Error during LLM summarization: {e}\"\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# MAIN EXECUTION\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- DEFINE YOUR PATHS HERE ---\n",
        "\n",
        "    # 1. Path to the folder with the 2 downloaded patent PDFs\n",
        "    PATENT_FOLDER = \"./fetched_patents\"\n",
        "\n",
        "    # 2. Path to YOUR uploaded PDF (the one you want to compare against)\n",
        "    #    *** YOU MUST CHANGE THIS PATH TO YOUR FILE ***\n",
        "    USER_PDF_PATH = \"./uploaded_patent/Funny_UFO_Wind_Communication_Patent.pdf\"\n",
        "\n",
        "    # 3. Path to store the persistent Chroma database\n",
        "    CHROMA_DB_PATH = \"my_patent_chroma_db\"\n",
        "\n",
        "    # --- END OF CONFIGURATION ---\n",
        "\n",
        "    if not OPENAI_API_KEY_SET:\n",
        "        print(\"Fatal Error: OPENAI_API_KEY is not set. The script cannot run.\")\n",
        "    elif not os.path.exists(PATENT_FOLDER):\n",
        "        print(f\"Fatal Error: Patent folder not found: {PATENT_FOLDER}\")\n",
        "    elif not os.path.exists(USER_PDF_PATH):\n",
        "        print(f\"Fatal Error: User PDF not found. Please update USER_PDF_PATH to point to your file: {USER_PDF_PATH}\")\n",
        "    else:\n",
        "        # 1. Initialize the collection\n",
        "        collection = init_collection(path=CHROMA_DB_PATH)\n",
        "\n",
        "        # 2. Populate the collection with the 2 patent PDFs (using fallback)\n",
        "        populate_collection(collection, PATENT_FOLDER)\n",
        "\n",
        "        # 3. Run the semantic comparison\n",
        "        print(\"\\n--- Running Semantic Comparison ---\")\n",
        "        final_summary = run_semantic_comparison(collection, USER_PDF_PATH)\n",
        "\n",
        "        print(\"\\n--- FINAL SUMMARY ---\")\n",
        "        print(final_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC9MnIzCOEq0",
        "outputId": "1bb5ed81-9177-40b6-ac10-d8024f80acd1"
      },
      "id": "OC9MnIzCOEq0",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Service 2] ChromaDB collection 'patent_comparison' loaded from path 'my_patent_chroma_db'.\n",
            "[Service 2] Cleared old patent data from ChromaDB.\n",
            "Found 2 patents to process in ./fetched_patents\n",
            "\n",
            "[Service 2] Processing patent file: 11214277.pdf...\n",
            "Attempting text extraction with pypdf for: ./fetched_patents/11214277.pdf\n",
            "Text successfully extracted with pypdf. Skipping OCR.\n",
            "[Service 2] Added 21 chunks for 11214277.pdf to collection.\n",
            "\n",
            "[Service 2] Processing patent file: 11214368.pdf...\n",
            "Attempting text extraction with pypdf for: ./fetched_patents/11214368.pdf\n",
            "Text successfully extracted with pypdf. Skipping OCR.\n",
            "[Service 2] Added 35 chunks for 11214368.pdf to collection.\n",
            "\n",
            "--- Running Semantic Comparison ---\n",
            "\n",
            "[Service 2] Parsing user PDF: ./uploaded_patent/Funny_UFO_Wind_Communication_Patent.pdf\n",
            "Attempting text extraction with pypdf for: ./uploaded_patent/Funny_UFO_Wind_Communication_Patent.pdf\n",
            "Text successfully extracted with pypdf. Skipping OCR.\n",
            "[Service 2] Querying ChromaDB with 1 chunks from user PDF...\n",
            "\n",
            "--- FINAL SUMMARY ---\n",
            "Based on the comparison results, the patent \"11214368.pdf\" has an average similarity score of 1.1287756204605102, which indicates a moderate level of similarity to your document \"Funny_UFO_Wind_Communication_Patent.pdf.\" The presence of 5 matching chunks suggests that there are several sections or concepts in the patent that overlap with your document.\n",
            "\n",
            "In semantic comparison, a lower average similarity score typically indicates a higher degree of relevance. However, in this case, since 1.1287756204605102 is the only score provided, we can conclude that \"11214368.pdf\" is the most relevant patent to your document, as it is the only one compared and has the lowest score available.\n",
            "\n",
            "In summary, \"11214368.pdf\" is the most relevant patent to your document due to its average similarity score being the lowest among the compared patents, along with the presence of multiple matching chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Service 3: seand email report to the lawyer"
      ],
      "metadata": {
        "id": "QBZE8oMdPaxG"
      },
      "id": "QBZE8oMdPaxG"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Imports ---\n",
        "import os\n",
        "import smtplib\n",
        "import ssl\n",
        "import getpass\n",
        "from email.message import EmailMessage\n",
        "from email.policy import SMTPUTF8  # UTF-8 aware policy\n",
        "\n",
        "# --- Config (env vars preferred; fallback to secure prompt at runtime) ---\n",
        "SENDER_EMAIL = os.environ.get(\"SENDER_EMAIL\")               # e.g., \"yourname@gmail.com\"\n",
        "SENDER_APP_PASSWORD = os.environ.get(\"SENDER_APP_PASSWORD\") # 16-char Gmail App Password (requires 2FA)\n",
        "EMAIL_CONFIG_SET = bool(SENDER_EMAIL and SENDER_APP_PASSWORD)\n",
        "\n",
        "def ensure_email_config():\n",
        "    \"\"\"\n",
        "    If EMAIL_CONFIG_SET is False, securely prompt for credentials once.\n",
        "    Returns True if config is set.\n",
        "    \"\"\"\n",
        "    global SENDER_EMAIL, SENDER_APP_PASSWORD, EMAIL_CONFIG_SET\n",
        "    if not EMAIL_CONFIG_SET:\n",
        "        print(\"Email credentials not found in environment. Enter them to proceed.\")\n",
        "        SENDER_EMAIL = input(\"Sender Gmail address: \").strip()\n",
        "        SENDER_APP_PASSWORD = getpass.getpass(\"Gmail App Password (won’t echo): \").strip()\n",
        "        EMAIL_CONFIG_SET = bool(SENDER_EMAIL and SENDER_APP_PASSWORD)\n",
        "    return EMAIL_CONFIG_SET\n",
        "\n",
        "def send_summary_email(\n",
        "    service_1_summary: str,\n",
        "    service_2_summary: str,\n",
        "    top_2_relevant_patents:str,\n",
        "    user_email: str,\n",
        "    lawyer_email: str\n",
        "):\n",
        "    \"\"\"\n",
        "    Sends a combined summary email to the lawyer via Gmail SMTP over SSL.\n",
        "\n",
        "    Notes for Gmail:\n",
        "    - Enable 2-Step Verification on the sender account.\n",
        "    - Create an App Password (Google Account → Security → App passwords).\n",
        "    - Use smtp.gmail.com:465 with SSL.\n",
        "    \"\"\"\n",
        "    if not EMAIL_CONFIG_SET:\n",
        "        print(\"Email credentials (SENDER_EMAIL, SENDER_APP_PASSWORD) not set. Skipping email.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n[Service 3] Preparing to send email to {lawyer_email}...\")\n",
        "\n",
        "    # --- Build the email body ---\n",
        "    email_body = f\"\"\"\n",
        "    Dear Legal Team,\n",
        "\n",
        "    Please find below a summary of a patent search conducted by {user_email}.\n",
        "\n",
        "    ========================================================\n",
        "    PART 1: INITIAL PATENT SEARCH\n",
        "    ========================================================\n",
        "\n",
        "    {service_1_summary}\n",
        "\n",
        "    The top 2 patents numbers for reference:\n",
        "    {top_2_relevant_patents}\n",
        "    ========================================================\n",
        "    PART 2: SEMANTIC COMPARISON\n",
        "    ========================================================\n",
        "\n",
        "    A user-provided document was semantically compared against the downloaded patents.\n",
        "    Here is the AI-generated analysis of the comparison:\n",
        "\n",
        "    {service_2_summary}\n",
        "\n",
        "\n",
        "    ========================================================\n",
        "\n",
        "    Please review these findings. You can reply directly to {user_email} with your assessment.\n",
        "\n",
        "    Best regards,\n",
        "    Patent Research Bot\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Create the Email Message Object (UTF-8 aware) ---\n",
        "    msg = EmailMessage(policy=SMTPUTF8)\n",
        "    msg[\"Subject\"] = \"Patent Research Summary for Review\"\n",
        "    msg[\"To\"] = lawyer_email\n",
        "    msg[\"From\"] = SENDER_EMAIL\n",
        "    msg.add_header(\"Reply-To\", user_email)\n",
        "\n",
        "    # Ensure body is UTF-8 safe (replace any problematic chars rather than fail)\n",
        "    safe_body = email_body.encode(\"utf-8\", \"replace\").decode(\"utf-8\")\n",
        "    msg.set_content(safe_body, subtype=\"plain\", charset=\"utf-8\")\n",
        "\n",
        "    # --- Send the Email ---\n",
        "    try:\n",
        "        context = ssl.create_default_context()\n",
        "        with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465, context=context) as server:\n",
        "            server.login(SENDER_EMAIL, SENDER_APP_PASSWORD)\n",
        "            # Ask server to accept UTF-8 (supported by Gmail)\n",
        "            server.send_message(msg, mail_options=[\"SMTPUTF8\"])\n",
        "            print(f\"[Service 3] Email successfully sent to {lawyer_email}!\")\n",
        "    except smtplib.SMTPException as e:\n",
        "        print(f\"[Service 3] Error: Unable to send email. {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[Service 3] An unexpected error occurred during email sending: {e}\")\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# MAIN EXECUTION\n",
        "# ---------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # If env vars are missing, prompt interactively once\n",
        "    if not ensure_email_config():\n",
        "        print(\"Invalid or missing email credentials. Skipping email service.\")\n",
        "    else:\n",
        "        user_email = input(\"Please enter your email address (for the lawyer to reply to): \").strip()\n",
        "        if not user_email or \"@\" not in user_email:\n",
        "            print(\"Invalid email address. Skipping email service.\")\n",
        "        else:\n",
        "\n",
        "            service_1 = llm_summary_object.summary_text  # noqa: F821\n",
        "\n",
        "\n",
        "            service_2 = final_summary\n",
        "\n",
        "            top2 = llm_summary_object.top_2_relevant_patents\n",
        "            numbers = [p.patent_number for p in top2]\n",
        "            numbers_str = \", \".join(numbers)\n",
        "\n",
        "            # Send the email\n",
        "            send_summary_email(\n",
        "                service_1_summary=service_1,\n",
        "                service_2_summary=service_2,\n",
        "                top_2_relevant_patents=numbers_str,\n",
        "                user_email=user_email,\n",
        "                lawyer_email=\"alimhdyassine@gmail.com\"\n",
        "            )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6dspQX6Pd_n",
        "outputId": "eb75336b-5b7f-4512-b82b-584cc878041e"
      },
      "id": "C6dspQX6Pd_n",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email credentials not found in environment. Enter them to proceed.\n",
            "Sender Gmail address: aliyassinove@gmail.com\n",
            "Gmail App Password (won’t echo): ··········\n",
            "Please enter your email address (for the lawyer to reply to): aliyassinove@gmail.com\n",
            "\n",
            "[Service 3] Preparing to send email to alimhdyassine@gmail.com...\n",
            "[Service 3] Email successfully sent to alimhdyassine@gmail.com!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio user interface"
      ],
      "metadata": {
        "id": "voJMfIpaSu6x"
      },
      "id": "voJMfIpaSu6x"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Simple Chatbot + Gradio wiring (per your 8 steps)\n",
        "# WITH SECURITY GUARDRAILS\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import gradio as gr\n",
        "\n",
        "# Expect these to be defined elsewhere in your project:\n",
        "# OPENAI_CLIENT, search_and_summarize_patents, download_patents,\n",
        "# load_st_model, ensure_email_config, send_summary_email,\n",
        "# init_collection, populate_collection, run_semantic_comparison,\n",
        "# EMAIL_CONFIG_SET\n",
        "\n",
        "# --- OpenAI function for emailing the report ---\n",
        "functions = [\n",
        "    {\n",
        "        \"name\": \"send_patent_summary_email\",\n",
        "        \"description\": \"Email the most recent patent search & comparison summary to a lawyer.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"user_email\":   {\"type\": \"string\", \"description\": \"Your email (reply-to).\"},\n",
        "                \"lawyer_email\": {\"type\": \"string\", \"description\": \"Lawyer/recipient email.\"}\n",
        "            },\n",
        "            \"required\": [\"user_email\", \"lawyer_email\"]\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "SAVE_DIRECTORY = \"./fetched_patents\"     # where top-2 patent PDFs are saved\n",
        "CHROMA_DB_PATH = \"my_patent_chroma_db\"   # persistent Chroma path\n",
        "\n",
        "# ============================================\n",
        "# GUARDRAILS AND SECURITY\n",
        "# ============================================\n",
        "\n",
        "def check_guardrails(user_input: str) -> tuple[bool, str]:\n",
        "    \"\"\"\n",
        "    Check if user input violates any guardrails.\n",
        "    Returns: (is_blocked, reason_message)\n",
        "\n",
        "    Protects against:\n",
        "    - System prompt access/manipulation attempts\n",
        "    - Restricted topics (cats, dogs, horoscopes, Taylor Swift)\n",
        "    - Prompt injection attempts\n",
        "    \"\"\"\n",
        "    if not user_input or not isinstance(user_input, str):\n",
        "        return False, \"\"\n",
        "\n",
        "    user_lower = user_input.lower()\n",
        "\n",
        "    # ============================================\n",
        "    # 1. SYSTEM PROMPT PROTECTION\n",
        "    # ============================================\n",
        "    system_prompt_keywords = [\n",
        "        # Direct prompt requests\n",
        "        \"system prompt\", \"system message\", \"systemprompt\",\n",
        "        \"show prompt\", \"reveal prompt\", \"display prompt\",\n",
        "        \"what is your prompt\", \"show me your prompt\",\n",
        "        \"what are your instructions\", \"show instructions\",\n",
        "        \"reveal your instructions\", \"display instructions\",\n",
        "        \"your system message\", \"initial instructions\",\n",
        "        \"base prompt\", \"original prompt\", \"core instructions\",\n",
        "\n",
        "        # Instruction manipulation\n",
        "        \"ignore previous\", \"ignore all previous\", \"ignore instructions\",\n",
        "        \"forget everything\", \"forget instructions\", \"disregard previous\",\n",
        "        \"override instructions\", \"bypass instructions\", \"new instructions\",\n",
        "        \"disregard instructions\", \"ignore above\", \"ignore earlier\",\n",
        "\n",
        "        # Role manipulation\n",
        "        \"pretend you are\", \"act as if\", \"roleplay as\",\n",
        "        \"you are now\", \"from now on you are\", \"behave as\",\n",
        "\n",
        "        # Information extraction\n",
        "        \"what were you told\", \"what are your rules\", \"your guidelines\",\n",
        "        \"your constraints\", \"your limitations\", \"your restrictions\",\n",
        "        \"how were you programmed\", \"what is your role\"\n",
        "    ]\n",
        "\n",
        "    for keyword in system_prompt_keywords:\n",
        "        if keyword in user_lower:\n",
        "            return True, (\n",
        "                \"⚠️ **Security Alert**: I cannot respond to requests about my system instructions \"\n",
        "                \"or attempts to modify my behavior. Please focus on patent search and innovation analysis.\"\n",
        "            )\n",
        "\n",
        "    # ============================================\n",
        "    # 2. RESTRICTED TOPICS\n",
        "    # ============================================\n",
        "    restricted_topics = {\n",
        "        \"Cats or Dogs\": [\n",
        "            \"cat\", \"cats\", \"feline\", \"kitten\", \"kitty\", \"meow\",\n",
        "            \"dog\", \"dogs\", \"canine\", \"puppy\", \"puppies\", \"bark\", \"woof\"\n",
        "        ],\n",
        "        \"Horoscopes or Zodiac Signs\": [\n",
        "            \"horoscope\", \"horoscopes\", \"zodiac\", \"astrology\", \"astrological\",\n",
        "            \"aries\", \"taurus\", \"gemini\", \"cancer\", \"leo\", \"virgo\",\n",
        "            \"libra\", \"scorpio\", \"sagittarius\", \"capricorn\", \"aquarius\", \"pisces\",\n",
        "            \"birth chart\", \"star sign\", \"sun sign\", \"moon sign\"\n",
        "        ],\n",
        "        \"Taylor Swift\": [\n",
        "            \"taylor swift\", \"taylorswift\", \"t swift\", \"tswift\", \"t.swift\",\n",
        "            \"taylor alison swift\", \"swiftie\", \"swifties\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Check each restricted topic\n",
        "    for topic_name, keywords in restricted_topics.items():\n",
        "        for keyword in keywords:\n",
        "            # Use word boundaries to avoid false positives\n",
        "            if keyword in user_lower:\n",
        "                # Additional check: make sure it's not part of a technical term\n",
        "                # Allow technical exceptions (e.g., \"catalyst\" shouldn't trigger \"cat\")\n",
        "                if len(keyword) <= 3:\n",
        "                    # For short keywords, check for word boundaries\n",
        "                    import re\n",
        "                    pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
        "                    if not re.search(pattern, user_lower):\n",
        "                        continue\n",
        "\n",
        "                return True, (\n",
        "                    f\"🚫 **Restricted Topic**: I cannot discuss **{topic_name}**. \"\n",
        "                    \"This chatbot is designed specifically for patent search and innovation analysis. \"\n",
        "                    \"Please describe your technical innovation or invention instead.\"\n",
        "                )\n",
        "\n",
        "    # ============================================\n",
        "    # 3. PROMPT INJECTION PROTECTION\n",
        "    # ============================================\n",
        "    injection_patterns = [\n",
        "        # Code blocks and formatting that might be injection attempts\n",
        "        \"```\", \"~~~\",\n",
        "        # Role markers\n",
        "        \"assistant:\", \"system:\", \"user:\", \"human:\", \"ai:\",\n",
        "        # Special tokens\n",
        "        \"<|\", \"|>\", \"[INST]\", \"[/INST]\", \"<s>\", \"</s>\",\n",
        "        # Template injection\n",
        "        \"{{\", \"}}\", \"${\",\n",
        "        # Script tags\n",
        "        \"<%\", \"%>\", \"<script\", \"</script>\",\n",
        "        # XML/HTML injection\n",
        "        \"<?\", \"?>\",\n",
        "        # Command separators\n",
        "        \"###assistant\", \"###system\", \"###user\"\n",
        "    ]\n",
        "\n",
        "    for pattern in injection_patterns:\n",
        "        if pattern in user_input:\n",
        "            return True, (\n",
        "                \"⚠️ **Input Validation Error**: Your input contains special characters or patterns \"\n",
        "                \"that cannot be processed. Please provide a plain text description of your innovation.\"\n",
        "            )\n",
        "\n",
        "    # ============================================\n",
        "    # 4. ADDITIONAL SAFETY CHECKS\n",
        "    # ============================================\n",
        "\n",
        "    # Check for excessive length (potential DOS or injection)\n",
        "    if len(user_input) > 5000:\n",
        "        return True, (\n",
        "            \"⚠️ **Input Too Long**: Please keep your innovation description under 5000 characters. \"\n",
        "            \"Focus on the key technical aspects of your invention.\"\n",
        "        )\n",
        "\n",
        "    # Check for excessive repetition (spam detection)\n",
        "    words = user_lower.split()\n",
        "    if len(words) > 10:\n",
        "        from collections import Counter\n",
        "        word_counts = Counter(words)\n",
        "        most_common_word, count = word_counts.most_common(1)[0]\n",
        "        if count > len(words) * 0.3:  # If any word appears more than 30% of the time\n",
        "            return True, (\n",
        "                \"⚠️ **Input Validation Error**: Your input appears to contain excessive repetition. \"\n",
        "                \"Please provide a clear, coherent description of your innovation.\"\n",
        "            )\n",
        "\n",
        "    return False, \"\"\n",
        "\n",
        "def chatbot(user_input: str, history=[], last_summary=None):\n",
        "    \"\"\"\n",
        "    Simplified flow with guardrails:\n",
        "      - First check guardrails for security violations\n",
        "      - Always treat the message as an innovation query (steps 2–4)\n",
        "      - Run the patent search with rows=200, top_k=500\n",
        "      - Download PDFs of the top-2\n",
        "      - Prompt to upload user's PDF for comparison (steps 5–6)\n",
        "      - Also support function-calling to send the report (steps 7–8)\n",
        "    Returns: (reply, history, new_summary_state, upload_btn_visibility)\n",
        "    \"\"\"\n",
        "    # ============================================\n",
        "    # GUARDRAIL CHECK - FIRST LINE OF DEFENSE\n",
        "    # ============================================\n",
        "    is_blocked, block_message = check_guardrails(user_input)\n",
        "    if is_blocked:\n",
        "        history.append((user_input, block_message))\n",
        "        return block_message, history, last_summary, gr.update(visible=False)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": (\"You check whether an innovation already exists using the US patent database, \"\n",
        "                     \"download the top-2 patent PDFs, compare the user's uploaded PDF against them, \"\n",
        "                     \"summarize results, and can email a report to a lawyer via a function call.\" )}\n",
        "    ]\n",
        "    for u, a in history:\n",
        "        if u is not None: messages.append({\"role\": \"user\", \"content\": u})\n",
        "        if a is not None: messages.append({\"role\": \"assistant\", \"content\": a})\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    upload_btn_visibility = gr.update(visible=False)\n",
        "\n",
        "    # ---- Run the innovation search (rows=200, top_k=500) ----\n",
        "    try:\n",
        "        try:\n",
        "            load_st_model()\n",
        "        except NameError:\n",
        "            pass\n",
        "\n",
        "        llm_summary = search_and_summarize_patents(\n",
        "            user_input,\n",
        "            top_k_claims_for_llm_ranking=8,\n",
        "            top_n_final_selection=2\n",
        "        )\n",
        "\n",
        "        if llm_summary:\n",
        "            os.makedirs(SAVE_DIRECTORY, exist_ok=True)\n",
        "            download_patents(llm_summary.top_2_relevant_patents, SAVE_DIRECTORY)\n",
        "\n",
        "            reply_parts = [llm_summary.summary_text, \"\\n**Top 2 most relevant patents:**\"]\n",
        "            for i, p in enumerate(llm_summary.top_2_relevant_patents, start=1):\n",
        "                reply_parts.append(\n",
        "                    f\"\\n— **{i}. {p.title} (US{p.patent_number})**\\n\"\n",
        "                    f\"*Date:* {p.publication_date}\\n\"\n",
        "                    f\"*Inventor(s):* {p.inventor}\\n\"\n",
        "                    f\"*Assignee(s):* {p.assignee}\\n\"\n",
        "                    f\"*Link:* {p.patent_link}\\n\"\n",
        "                    f\"{'* PDF: ' + str(getattr(p, 'pdf_link', None)) if getattr(p, 'pdf_link', None) else '* PDF:* (not available)'}\\n\"\n",
        "                    f\"*Abstract:* {p.snippet}\"\n",
        "                )\n",
        "\n",
        "            reply_parts.append(\n",
        "                \"\\n---\\n**Next:** Please **upload a PDF** describing your innovation and I'll compare it against these two patents.\"\n",
        "            )\n",
        "            reply_parts.append(\n",
        "                \"\\n*After the comparison*: say `Send the report` and include `user_email` and `lawyer_email` \"\n",
        "                \"to email the results (you may be prompted for server email credentials if not set).\"\n",
        "            )\n",
        "\n",
        "            final_reply = \"\\n\".join(reply_parts)\n",
        "            history.append((user_input, final_reply))\n",
        "\n",
        "            # Make upload button visible for step 5\n",
        "            upload_btn_visibility = gr.update(visible=True)\n",
        "            return final_reply, history, llm_summary, upload_btn_visibility\n",
        "\n",
        "        else:\n",
        "            msg = (\"I couldn't retrieve enough patent information for your query. \"\n",
        "                   \"Please add more technical detail (components, function, use-case).\")\n",
        "            history.append((user_input, msg))\n",
        "            return msg, history, last_summary, upload_btn_visibility\n",
        "\n",
        "    except Exception as e:\n",
        "        err = f\"An error occurred while searching patents: {e}\"\n",
        "        history.append((user_input, err))\n",
        "        return err, history, last_summary, upload_btn_visibility\n",
        "\n",
        "def _uploaded_file_path(file_obj):\n",
        "    \"\"\"\n",
        "    Return a real, existing path from a Gradio upload (handles multiple shapes).\n",
        "    Raises FileNotFoundError if no valid path is found.\n",
        "    \"\"\"\n",
        "    # direct string path\n",
        "    if isinstance(file_obj, str) and os.path.exists(file_obj):\n",
        "        return file_obj\n",
        "\n",
        "    # gradio File/TempFile-like objects\n",
        "    for attr in (\"name\", \"path\"):\n",
        "        p = getattr(file_obj, attr, None)\n",
        "        if isinstance(p, str) and os.path.exists(p):\n",
        "            return p\n",
        "\n",
        "    # dict-like payloads (some gradio versions)\n",
        "    if isinstance(file_obj, dict):\n",
        "        for key in (\"name\", \"path\", \"tempfile\", \"file\"):\n",
        "            p = file_obj.get(key)\n",
        "            if isinstance(p, str) and os.path.exists(p):\n",
        "                return p\n",
        "\n",
        "    raise FileNotFoundError(f\"Could not resolve upload path from: {repr(file_obj)}\")\n",
        "\n",
        "def handle_pdf_upload(pdf_file, history, summary_state):\n",
        "    \"\"\"\n",
        "    Compare the uploaded PDF against the two saved patent PDFs and summarize results.\n",
        "    \"\"\"\n",
        "    if not summary_state:\n",
        "        msg = \"Run a patent search first, then upload your PDF.\"\n",
        "        history.append((None, msg))\n",
        "        return history, gr.update(visible=False)\n",
        "\n",
        "    try:\n",
        "        os.makedirs(SAVE_DIRECTORY, exist_ok=True)\n",
        "        collection = init_collection(path=CHROMA_DB_PATH)\n",
        "        ok = populate_collection(collection, SAVE_DIRECTORY)\n",
        "        if not ok:\n",
        "            msg = \"I couldn't prepare the two patent PDFs for comparison.\"\n",
        "            history.append((f\"(Uploaded {getattr(pdf_file, 'name', 'uploaded.pdf')})\", msg))\n",
        "            return history, gr.update(visible=False)\n",
        "    except Exception as e:\n",
        "        msg = f\"Error preparing comparison DB: {e}\"\n",
        "        history.append((f\"(Uploaded {getattr(pdf_file, 'name', 'uploaded.pdf')})\", msg))\n",
        "        return history, gr.update(visible=False)\n",
        "\n",
        "    # ✅ robust path resolution\n",
        "    try:\n",
        "        uploaded_path = _uploaded_file_path(pdf_file)\n",
        "    except Exception as e:\n",
        "        msg = f\"Upload error: couldn't read the file path ({e}).\"\n",
        "        history.append((f\"(Uploaded ?)\", msg))\n",
        "        return history, gr.update(visible=False)\n",
        "\n",
        "    # Run the semantic comparison\n",
        "    try:\n",
        "        final_summary = run_semantic_comparison(collection, uploaded_path) or \"No comparison results.\"\n",
        "    except Exception as e:\n",
        "        final_summary = f\"Comparison failed: {e}\"\n",
        "\n",
        "    decorated = (\n",
        "        f\"**FINAL COMPARISON SUMMARY**\\n\\n\"\n",
        "        f\"Uploaded: `{os.path.basename(str(uploaded_path))}`\\n\\n\"\n",
        "        f\"{final_summary}\\n\\n\"\n",
        "        f\"To email this report, say:\\n\"\n",
        "        f\"`Send the report user_email=you@example.com lawyer_email=counsel@example.com`\"\n",
        "    )\n",
        "    history.append((f\"(Uploaded {os.path.basename(str(uploaded_path))})\", decorated))\n",
        "    return history, gr.update(visible=False)\n",
        "\n",
        "# -----------------------\n",
        "# Gradio UI (with loading)\n",
        "# -----------------------\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# 🤖 Innovation Patent Checker (Secured)\")\n",
        "    gr.Markdown(\n",
        "        \"1) Enter your innovation → 2) I search & summarize → 3) Upload your PDF → \"\n",
        "        \"4) I compare vs top-2 patents → 5) Provide emails to send the report.\\n\\n\"\n",
        "        \"⚠️ **Security Notice**: This system has guardrails to protect against unauthorized access \"\n",
        "        \"and is restricted to patent analysis only.\"\n",
        "    )\n",
        "\n",
        "    last_summary = gr.State(None)\n",
        "    chatbot_ui   = gr.Chatbot(label=\"Chatbot\", height=520)\n",
        "    user_input   = gr.Textbox(placeholder=\"Describe your innovation...\", label=\"Your Idea\")\n",
        "    submit_btn   = gr.Button(\"Run Search\", variant=\"primary\")\n",
        "\n",
        "    pdf_upload_btn = gr.UploadButton(\"Upload Your Innovation PDF\", file_types=[\".pdf\"], visible=False)\n",
        "\n",
        "    def respond(msg, history, summary_state):\n",
        "        \"\"\"\n",
        "        Generator so the UI shows a 'Searching…' bubble while the long call runs in the background.\n",
        "        \"\"\"\n",
        "        clear = \"\"\n",
        "        temp = (history or []) + [(msg, \"Searching the US patent database…\")]\n",
        "        yield clear, temp, summary_state, gr.update(visible=False)\n",
        "        # Actual work:\n",
        "        reply, updated_history, new_summary, upload_viz = chatbot(msg, history or [], summary_state)\n",
        "        yield clear, updated_history, new_summary, upload_viz\n",
        "\n",
        "    submit_btn.click(\n",
        "        respond,\n",
        "        inputs=[user_input, chatbot_ui, last_summary],\n",
        "        outputs=[user_input, chatbot_ui, last_summary, pdf_upload_btn],\n",
        "    )\n",
        "    user_input.submit(\n",
        "        respond,\n",
        "        inputs=[user_input, chatbot_ui, last_summary],\n",
        "        outputs=[user_input, chatbot_ui, last_summary, pdf_upload_btn],\n",
        "    )\n",
        "\n",
        "    pdf_upload_btn.upload(\n",
        "        handle_pdf_upload,\n",
        "        inputs=[pdf_upload_btn, chatbot_ui, last_summary],\n",
        "        outputs=[chatbot_ui, pdf_upload_btn],\n",
        "    )\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            \"A catheter that can do both IVUS and OCT in a single pullback\",\n",
        "            \"A wearable that measures glucose non-invasively with Raman spectroscopy\",\n",
        "        ],\n",
        "        inputs=user_input,\n",
        "    )\n",
        "\n",
        "# ---- Optional warmups and launch ----\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        load_st_model()\n",
        "    except NameError:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        if not EMAIL_CONFIG_SET:\n",
        "            print(\"Note: Email credentials not set; you'll be prompted if you send a report.\")\n",
        "    except NameError:\n",
        "        pass\n",
        "\n",
        "    demo.launch(share=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "lJf1o_HSRfNN",
        "outputId": "ac7d753d-c634-4ba9-ba81-1bb5bdad1a81"
      },
      "id": "lJf1o_HSRfNN",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3383312317.py:352: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot_ui   = gr.Chatbot(label=\"Chatbot\", height=520)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading SentenceTransformer 'all-MiniLM-L6-v2' on device: cpu\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7863, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "deploying-ai-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}